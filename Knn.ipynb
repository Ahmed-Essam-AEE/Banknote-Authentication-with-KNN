{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset and null checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      variance  skewness  curtosis  entropy  class\n",
      "0      3.62160   8.66610   -2.8073 -0.44699      0\n",
      "1      4.54590   8.16740   -2.4586 -1.46210      0\n",
      "2      3.86600  -2.63830    1.9242  0.10645      0\n",
      "3      3.45660   9.52280   -4.0112 -3.59440      0\n",
      "4      0.32924  -4.45520    4.5718 -0.98880      0\n",
      "...        ...       ...       ...      ...    ...\n",
      "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
      "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
      "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
      "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
      "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
      "\n",
      "[1372 rows x 5 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   variance  1372 non-null   float64\n",
      " 1   skewness  1372 non-null   float64\n",
      " 2   curtosis  1372 non-null   float64\n",
      " 3   entropy   1372 non-null   float64\n",
      " 4   class     1372 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"BankNote_Authentication.csv\")\n",
    "#normalized = pd.read_csv(\"BankNote_Authentication.csv\")\n",
    "print(data)\n",
    "#print(f\"null values: {data.isnull().sum()}\")\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data\n",
    "    divide dataset into 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      variance  skewness  curtosis  entropy\n",
      "0      3.62160   8.66610   -2.8073 -0.44699\n",
      "1      4.54590   8.16740   -2.4586 -1.46210\n",
      "2      3.86600  -2.63830    1.9242  0.10645\n",
      "3      3.45660   9.52280   -4.0112 -3.59440\n",
      "4      0.32924  -4.45520    4.5718 -0.98880\n",
      "...        ...       ...       ...      ...\n",
      "1367   0.40614   1.34920   -1.4501 -0.55949\n",
      "1368  -1.38870  -4.87730    6.4774  0.34179\n",
      "1369  -3.75030 -13.45860   17.5932 -2.77710\n",
      "1370  -3.56370  -8.38270   12.3930 -1.28230\n",
      "1371  -2.54190  -0.65804    2.6842  1.19520\n",
      "\n",
      "[1372 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['class'])\n",
    "Y = data['class']\n",
    "print(X)\n",
    "#print(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizating each feature separately:\n",
    "    using the mean and std of the values of that feature column on the TRAINING data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      variance  skewness  curtosis  entropy\n",
      "1007  -0.17296   -1.1816   1.38180  0.73360\n",
      "1176  -0.59587    2.4811  -2.86730 -0.89828\n",
      "332    3.55940    1.3078   1.29100  1.65560\n",
      "585    4.33980   -5.3036   3.88030 -0.70432\n",
      "52     3.14520    5.8250  -0.51439 -1.49440\n",
      "...        ...       ...       ...      ...\n",
      "112    3.23510    9.6470  -3.20740 -2.59480\n",
      "1214  -2.96620  -10.3257   8.78400 -2.11380\n",
      "588   -0.27802    8.1881  -3.13380 -2.52760\n",
      "984   -0.69745   -1.7672  -0.34474 -0.12372\n",
      "1187  -4.02180   -8.3040  12.55500 -1.50990\n",
      "\n",
      "[412 rows x 4 columns]\n",
      "------------ After normalizing -------------- \n",
      "      variance  skewness  curtosis   entropy\n",
      "1007 -0.201353 -0.529889 -0.001733  0.955527\n",
      "1176 -0.351226  0.082355 -0.967885  0.180776\n",
      "332   1.121348 -0.113770 -0.022379  1.393255\n",
      "585   1.397912 -1.218908  0.566371  0.272860\n",
      "52    0.974561  0.641310 -0.432885 -0.102238\n",
      "...        ...       ...       ...       ...\n",
      "112   1.006421  1.280182 -1.045216 -0.624664\n",
      "1214 -1.191241 -2.058385  1.681365 -0.396304\n",
      "588  -0.238584  1.036317 -1.028481 -0.592760\n",
      "984  -0.387225 -0.627776 -0.394310  0.548506\n",
      "1187 -1.565333 -1.720444  2.538808 -0.109597\n",
      "\n",
      "[412 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "print(x_test)\n",
    "\"\"\"for i in range(x_train.shape[0]):\n",
    "    for j in range(x_train.shape[1]):\n",
    "        x_train.iloc[i,j] = (x_train.iloc[i,j] - x_train.iloc[: , j].mean() ) \"\"\"\n",
    "\n",
    "for i  in range(x_test.shape[0]):\n",
    "    for j in range(x_test.shape[1]):\n",
    "        x_test.iloc[i][j] = (x_test.iloc[i][j] - x_train.iloc[: , j].mean()) / x_train.iloc[: , j].std()\n",
    "\n",
    "for i  in range(x_train.shape[0]):\n",
    "    for j in range(x_train.shape[1]): \n",
    "        x_train.iloc[i][j] = (x_train.iloc[i][j] - x_train.iloc[: , j].mean()) / x_train.iloc[: , j].std()\n",
    "\n",
    "    \n",
    "    #x_train[i] = (x_train[i] - x_train[i].mean()) / x_train[i].std()\n",
    "    #x_test[i] = (x_test[i] - x_train[i].mean()) / x_train[i].std()\n",
    "    #print(x_test[i])\n",
    "\n",
    "print(\"------------ After normalizing -------------- \")\n",
    "print(x_test)\n",
    "\n",
    "#first_element = y_train[0]\n",
    "#print(first_element)\n",
    "\n",
    "#print(x_train.info())\n",
    "#print(x_test.info())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN implementation:\n",
    "     If there is a tie in the class predicted by the k -nearest neighbors, then among the classes that have the same number of votes, the tie should be broken in favor of the class that comes first in the Train file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x , data):\n",
    "    return np.sqrt( np.sum( np.square( x - data ) ) )\n",
    "\n",
    "class KnnClassifier():\n",
    "    def __init__(self , knn=3 ,  parametric=euclidean_distance ):\n",
    "        self.k=knn\n",
    "        self.param = parametric\n",
    "    \n",
    "    def fit(self , x_train , y_train):\n",
    "        self.x_train=x_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self , x_test):\n",
    "        hx=[]\n",
    "        j=0\n",
    "        for x1 in x_test.values:\n",
    "            #print(x1)\n",
    "            distances = np.zeros(self.x_train.shape[0])\n",
    "            i=0\n",
    "            for x2 in self.x_train.values:\n",
    "                dist  = euclidean_distance(x1 , x2)\n",
    "                distances[i] = dist\n",
    "                i+=1\n",
    "            sorted_inds = distances.argsort()\n",
    "            y = [y for dis , y in sorted( zip(distances , self.y_train))]\n",
    "            y = y[:self.k]\n",
    "\n",
    "\n",
    "            n1 =0 \n",
    "            n0=0\n",
    "            for i in y:\n",
    "                if i == 1:\n",
    "                    n1+=1\n",
    "                elif i == 0:\n",
    "                    n0+=1\n",
    "            if n1>n0:\n",
    "                hx.append(1)\n",
    "            elif n1==n0:\n",
    "                hx.append(self.y_train.shape[0])\n",
    "            else:\n",
    "                hx.append(0)\n",
    "         \n",
    "        \n",
    "        return np.array(hx)\n",
    "    \n",
    "    def accuracy(self , y , hx):\n",
    "        return np.sum(y==hx) / len(y)\n",
    "\n",
    "\n",
    "model = KnnClassifier(5)\n",
    "model.fit(x_train , y_train)\n",
    "hx = model.predict(x_test)\n",
    "\n",
    "#for i in (x_train.values):\n",
    "    #print(i)\n",
    "#print(hx)\n",
    "\n",
    "#print(y_test)\n",
    "\n",
    "#print(\"Accuracy: \" , model.accuracy(y_test , hx) * 100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing:\n",
    "     Experiment with different values of k=1,2,3....9 and output The value of k used for the test set on the first line followed by summary info for the current k value: number of correctly classified test instances, and the total number of instances in the test set and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k value: 1\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 408 \n",
      "Accuracy : 0.9902912621359223\n",
      "----------------------------------------------------------\n",
      "k value: 2\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 408 \n",
      "Accuracy : 0.9902912621359223\n",
      "----------------------------------------------------------\n",
      "k value: 3\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 408 \n",
      "Accuracy : 0.9902912621359223\n",
      "----------------------------------------------------------\n",
      "k value: 4\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 406 \n",
      "Accuracy : 0.9854368932038835\n",
      "----------------------------------------------------------\n",
      "k value: 5\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 406 \n",
      "Accuracy : 0.9854368932038835\n",
      "----------------------------------------------------------\n",
      "k value: 6\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 404 \n",
      "Accuracy : 0.9805825242718447\n",
      "----------------------------------------------------------\n",
      "k value: 7\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 407 \n",
      "Accuracy : 0.9878640776699029\n",
      "----------------------------------------------------------\n",
      "k value: 8\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 404 \n",
      "Accuracy : 0.9805825242718447\n",
      "----------------------------------------------------------\n",
      "k value: 9\n",
      "Total number of instances : 412\n",
      "Number of correctly classified instances : 404 \n",
      "Accuracy : 0.9805825242718447\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1 , 10 , 1):\n",
    "    model = KnnClassifier(i)\n",
    "    model.fit(x_train , y_train)\n",
    "    hx = model.predict(x_test)\n",
    "\n",
    "    print(f\"k value: {i}\")\n",
    "    print(f\"Total number of instances : {x_test.shape[0]}\")\n",
    "    print(f\"Number of correctly classified instances : {np.sum(y_test==hx)} \")\n",
    "    print(f\"Accuracy : {model.accuracy(y_test , hx)}\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1 (tags/v3.8.1:1b293b6, Dec 18 2019, 22:39:24) [MSC v.1916 32 bit (Intel)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ea1bb99331e10e7e496a31bf4157556045a88212074203292dd30ac2bc817e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
